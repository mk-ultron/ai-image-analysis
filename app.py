import streamlit as st
import anthropic
import openai
from PIL import Image
import io
import sqlite3
import base64
from exif import Image as ExifImage
import tempfile
import os
import hashlib
import requests

# Set page configuration
st.set_page_config(
    page_title="AI Image Analysis with TTS",
    page_icon="ðŸ”¥",
    layout="centered",
    initial_sidebar_state="auto"
)

def setup_database():
    """
    Set up and migrate the SQLite database for storing image analysis results.
    
    Returns:
        tuple: A connection object and a cursor object for database operations.
    """
    conn = sqlite3.connect('image_analysis.db')
    c = conn.cursor()
    
    # Check if the images table exists
    c.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='images'")
    table_exists = c.fetchone()
    
    if not table_exists:
        # Create the table if it doesn't exist
        c.execute('''CREATE TABLE images
                     (id INTEGER PRIMARY KEY,
                      image_hash TEXT NOT NULL UNIQUE,
                      make TEXT NOT NULL,
                      model TEXT NOT NULL,
                      datetime TEXT NOT NULL,
                      gps_latitude TEXT,
                      gps_longitude TEXT,
                      analysis TEXT NOT NULL,
                      timestamp DATETIME DEFAULT CURRENT_TIMESTAMP)''')
    else:
        # Perform migration if necessary
        c.execute("PRAGMA table_info(images)")
        columns = [column[1] for column in c.fetchall()]
        
        if 'make' not in columns:
            # Migrate to new schema
            c.execute('''CREATE TABLE images_new
                         (id INTEGER PRIMARY KEY,
                          image_hash TEXT NOT NULL UNIQUE,
                          make TEXT NOT NULL,
                          model TEXT NOT NULL,
                          datetime TEXT NOT NULL,
                          gps_latitude TEXT,
                          gps_longitude TEXT,
                          analysis TEXT NOT NULL,
                          timestamp DATETIME DEFAULT CURRENT_TIMESTAMP)''')
            
            # Copy data from old table to new table
            c.execute('''INSERT INTO images_new (image_hash, make, model, datetime, gps_latitude, gps_longitude, analysis)
                         SELECT image_hash, 
                                'Unknown' as make, 
                                'Unknown' as model, 
                                'Unknown' as datetime, 
                                'Unknown' as gps_latitude, 
                                'Unknown' as gps_longitude, 
                                analysis 
                         FROM images''')
            
            # Replace old table with new table
            c.execute("DROP TABLE images")
            c.execute("ALTER TABLE images_new RENAME TO images")
            
            st.success("Database schema has been updated successfully!")
    
    # Create an index on the image_hash column for faster lookups
    c.execute('CREATE INDEX IF NOT EXISTS idx_image_hash ON images(image_hash)')
    
    conn.commit()
    return conn, c

# Set up database connection and cursor
conn, c = setup_database()

# Initialize API clients
anthropic_client = anthropic.Anthropic(api_key=st.secrets["api_keys"]["anthropic"])
openai_client = openai.OpenAI(api_key=st.secrets["api_keys"]["openai"])

# Initialize session state for storing analyzed images
if 'analyzed_images' not in st.session_state:
    st.session_state.analyzed_images = []

def extract_metadata(image_bytes):
    """
    Extract metadata from an image file.
    
    Args:
        image_bytes (bytes): The image file in bytes.
    
    Returns:
        dict: A dictionary containing the extracted metadata.
    """
    try:
        img = ExifImage(image_bytes)
        metadata = {
            "make": img.get("make", "Unknown"),
            "model": img.get("model", "Unknown"),
            "datetime": img.get("datetime", "Unknown"),
            "gps_latitude": str(img.get("gps_latitude", "Unknown")),
            "gps_longitude": str(img.get("gps_longitude", "Unknown")),
        }
    except Exception as e:
        # If metadata extraction fails, return default values
        metadata = {
            "make": "Unknown",
            "model": "Unknown",
            "datetime": "Unknown",
            "gps_latitude": "Unknown",
            "gps_longitude": "Unknown",
        }
    return metadata

def analyze_image_with_claude(image_base64, metadata):
    """
    Analyze an image using Claude AI model.
    
    Args:
        image_base64 (str): Base64 encoded image data.
        metadata (dict): Image metadata.
    
    Returns:
        str: The analysis text generated by Claude.
    """
    prompt = f"""
    Analyze the following image and provide a detailed description. 
    Consider the following aspects:
    1. Main subject(s) of the image
    2. Any pop culture references or recognizable figures?
    3. What text is visible in the image, and what can you infer about the image from it? In 1-2 sentences, describe what do you know about what the text might represent. 
    4. What is the style of the image (e.g., realism, abstract, impressionism, colors and overall mood)

    Additional context from metadata:
    - Camera: {metadata['make']} {metadata['model']}
    - Date taken: {metadata['datetime']}
    - GPS coordinates: {metadata['gps_latitude']}, {metadata['gps_longitude']}

    Provide a comprehensive analysis in about 100-300 words.
    """

    response = anthropic_client.messages.create(
        model="claude-3-5-sonnet-20240620",
        max_tokens=500,
        messages=[
            {
                "role": "user",
                "content": [
                    {
                        "type": "image",
                        "source": {
                            "type": "base64",
                            "media_type": "image/jpeg",
                            "data": image_base64
                        }
                    },
                    {
                        "type": "text",
                        "text": prompt
                    }
                ]
            }
        ]
    )
    
    return response.content[0].text

def text_to_speech(text, voice="alloy"):
    """
    Convert text to speech using OpenAI's TTS model.
    
    Args:
        text (str): The text to convert to speech.
        voice (str, optional): The voice to use for TTS. Defaults to "alloy".
    
    Returns:
        str: The path to the temporary audio file.
    """
    response = openai_client.audio.speech.create(
        model="tts-1",
        voice=voice,
        input=text
    )
    
    # Save the audio content to a temporary file
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as temp_audio:
        for chunk in response.iter_bytes(chunk_size=1024 * 1024):
            temp_audio.write(chunk)
    
    return temp_audio.name

def resize_image(image, max_size=(1568, 1568), max_pixels=1150000):
    """
    Resize an image while maintaining aspect ratio and not exceeding max dimensions or pixel count.
    
    Args:
        image (PIL.Image): The image to resize.
        max_size (tuple, optional): Maximum width and height. Defaults to (1568, 1568).
        max_pixels (int, optional): Maximum number of pixels. Defaults to 1150000.
    
    Returns:
        PIL.Image: The resized image.
    """
    width, height = image.size
    num_pixels = width * height
    
    if num_pixels <= max_pixels and width <= max_size[0] and height <= max_size[1]:
        return image
    
    scale = min(
        (max_pixels / num_pixels) ** 0.5,
        max_size[0] / width,
        max_size[1] / height
    )
    
    new_width = int(width * scale)
    new_height = int(height * scale)
    
    return image.resize((new_width, new_height), Image.LANCZOS)

def get_image_hash(image_bytes):
    """
    Generate a hash for an image.
    
    Args:
        image_bytes (bytes): The image data in bytes.
    
    Returns:
        str: The MD5 hash of the image.
    """
    return hashlib.md5(image_bytes).hexdigest()

def display_analysis_card(image, analysis, image_hash):
    """
    Display an analysis card for an image, including the image, analysis text, and audio playback option.
    
    Args:
        image (PIL.Image): The image to display.
        analysis (str): The analysis text.
        image_hash (str): The hash of the image for unique key generation.
    """
    st.write("---")
    col1, col2 = st.columns([1, 3])
    with col1:
        st.image(image, use_column_width=True)
    with col2:
        st.write(analysis)
        play_button_key = f"play_{image_hash}"
        if st.button(f"Play Analysis", key=play_button_key):
            with st.spinner("Generating audio..."):
                try:
                    audio_file_path = text_to_speech(analysis)
                    st.audio(audio_file_path, format='audio/mp3')
                except Exception as e:
                    st.error(f"An error occurred while generating the audio: {str(e)}")
                finally:
                    if 'audio_file_path' in locals():
                        os.remove(audio_file_path)

def load_image_from_url(url):
    """
    Load an image from a given URL.
    
    Args:
        url (str): The URL of the image.
    
    Returns:
        PIL.Image: The loaded image.
    """
    response = requests.get(url)
    image = Image.open(io.BytesIO(response.content))
    return image

def get_analysis_by_hash(image_hash):
    """
    Retrieve the analysis for an image from the database using its hash.
    
    Args:
        image_hash (str): The hash of the image.
    
    Returns:
        str: The analysis text, or None if not found.
    """
    c.execute("SELECT analysis FROM images WHERE image_hash = ?", (image_hash,))
    result = c.fetchone()
    return result[0] if result else None

def insert_analysis(image_hash, metadata, analysis):
    """
    Insert a new image analysis into the database.
    
    Args:
        image_hash (str): The hash of the image.
        metadata (dict): The image metadata.
        analysis (str): The analysis text.
    """
    c.execute("""
        INSERT INTO images (image_hash, make, model, datetime, gps_latitude, gps_longitude, analysis)
        VALUES (?, ?, ?, ?, ?, ?, ?)
    """, (
        image_hash,
        metadata['make'],
        metadata['model'],
        metadata['datetime'],
        metadata['gps_latitude'],
        metadata['gps_longitude'],
        analysis
    ))
    conn.commit()

def get_or_create_analysis(image_hash, metadata, image_base64):
    """
    Retrieve an existing analysis or create a new one if it doesn't exist.
    
    Args:
        image_hash (str): The hash of the image.
        metadata (dict): The image metadata.
        image_base64 (str): The base64 encoded image data.
    
    Returns:
        str: The analysis text.
    """
    existing_analysis = get_analysis_by_hash(image_hash)
    if existing_analysis:
        return existing_analysis
    
    analysis = analyze_image_with_claude(image_base64, metadata)
    insert_analysis(image_hash, metadata, analysis)
    return analysis

def process_image(image, source_type):
    """
    Process an uploaded or URL-loaded image, including resizing, analysis, and display.
    
    Args:
        image (PIL.Image): The image to process.
        source_type (str): The source of the image ('upload' or 'url').
    """
    resized_image = resize_image(image)
    
    image_bytes = io.BytesIO()
    resized_image.save(image_bytes, format="JPEG")
    image_bytes = image_bytes.getvalue()
    image_hash = get_image_hash(image_bytes)

    st.image(resized_image, caption='Processed Image (Resized)', use_column_width=True)

    button_key = f"analyze_{source_type}_{image_hash}"

    if st.button("Analyze Image", key=button_key):
        with st.spinner("Analyzing image..."):
            metadata = extract_metadata(image_bytes)
            img_base64 = base64.b64encode(image_bytes).decode('utf-8')
            
            analysis = get_or_create_analysis(image_hash, metadata, img_base64)

            st.session_state.analyzed_images.insert(0, {
                'image': resized_image,
                'analysis': analysis,
                'image_hash': image_hash
            })

            st.success("Analysis complete!")
            st.write(analysis)

def main():
    """
    Main function to run the Streamlit app.
    """
    st.title("AI Image Analysis with TTS")

    # Create tabs for upload and URL input
    tab1, tab2 = st.tabs(["Upload Image", "Enter Image URL"])

    with tab1:
        uploaded_file = st.file_uploader("Choose an image...", type=["jpg", "jpeg", "png"])
        if uploaded_file is not None:
            image = Image.open(uploaded_file)
            process_image(image, "upload")

    with tab2:
        url = st.text_input("Enter the URL of an image:")
        if url:
            try:
                image = load_image_from_url(url)
                process_image(image, "url")
            except Exception as e:
                st.error(f"Error loading image from URL: {str(e)}")

    # Display previously analyzed images
    for data in st.session_state.analyzed_images:
        display_analysis_card(data['image'], data['analysis'], data['image_hash'])

if __name__ == "__main__":
    main()
